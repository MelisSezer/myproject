{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1c65ff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Veri çekme aralığı: 2018-07-14 - 2025-07-12\n",
      "AU bbox 112.552738,-39.144150,153.685550,-11.567325 içindeki sensörler çekiliyor...\n",
      "Sayfa 1 çekildi, 245 konum eklendi\n",
      "\n",
      "Toplam 893 sensör için GÜNLÜK veri çekiliyor...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sensör Verileri Çekiliyor:   4%|▍         | 38/893 [01:02<25:32,  1.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sensör 28917 için hata (Sayfa 3): Rate limit exceeded. Limit resets in 4 seconds. Bekleniyor...\n",
      "5 saniye bekleniyor...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sensör Verileri Çekiliyor:   8%|▊         | 67/893 [02:08<15:36,  1.13s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sensör 12210358 için hata (Sayfa 2): Rate limit exceeded. Limit resets in 3 seconds. Bekleniyor...\n",
      "4 saniye bekleniyor...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sensör Verileri Çekiliyor:   9%|▊         | 76/893 [02:34<27:44,  2.04s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 72\u001b[39m\n\u001b[32m     70\u001b[39m sensor_ids, sensor_country_map = get_sensor_ids(BBOX_AU, client, COUNTRY_CODE)\n\u001b[32m     71\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m sensor_ids:\n\u001b[32m---> \u001b[39m\u001b[32m72\u001b[39m     raw_df = \u001b[43mget_daily_by_sid\u001b[49m\u001b[43m(\u001b[49m\u001b[43msensor_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbaslangic_date_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbitis_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msensor_country_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     73\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m raw_df.empty:\n\u001b[32m     74\u001b[39m         raw_df.to_csv(RAW_DATA_FILE, index=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 43\u001b[39m, in \u001b[36mget_daily_by_sid\u001b[39m\u001b[34m(sids, baslangic, end, sensor_map, sleep_time)\u001b[39m\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m     42\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m         resp = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmeasurements\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlist\u001b[49m\u001b[43m(\u001b[49m\u001b[43msensors_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43msid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdays\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatetime_from\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbaslangic\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatetime_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpage\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     44\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m resp.results: \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m     45\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m resp.results:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\melis\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\openaq\\_sync\\models\\measurements.py:72\u001b[39m, in \u001b[36mMeasurements.list\u001b[39m\u001b[34m(self, sensors_id, data, rollup, datetime_from, datetime_to, page, limit)\u001b[39m\n\u001b[32m     64\u001b[39m params = build_query_params(\n\u001b[32m     65\u001b[39m     page=page,\n\u001b[32m     66\u001b[39m     limit=limit,\n\u001b[32m     67\u001b[39m     datetime_from=datetime_from,\n\u001b[32m     68\u001b[39m     datetime_to=datetime_to,\n\u001b[32m     69\u001b[39m )\n\u001b[32m     70\u001b[39m path = build_measurements_path(sensors_id, data, rollup)\n\u001b[32m---> \u001b[39m\u001b[32m72\u001b[39m measurements_response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_get\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m MeasurementsResponse.read_response(measurements_response)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\melis\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\openaq\\_sync\\client.py:106\u001b[39m, in \u001b[36mOpenAQ._get\u001b[39m\u001b[34m(self, path, params, headers)\u001b[39m\n\u001b[32m     99\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34m_get\u001b[39m(\n\u001b[32m    100\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    101\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    104\u001b[39m     headers: Mapping[\u001b[38;5;28mstr\u001b[39m, Any] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    105\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_do\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mget\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\melis\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\openaq\\_sync\\client.py:93\u001b[39m, in \u001b[36mOpenAQ._do\u001b[39m\u001b[34m(self, method, path, params, headers)\u001b[39m\n\u001b[32m     91\u001b[39m request_headers = \u001b[38;5;28mself\u001b[39m.build_request_headers(headers)\n\u001b[32m     92\u001b[39m url = \u001b[38;5;28mself\u001b[39m._base_url + path\n\u001b[32m---> \u001b[39m\u001b[32m93\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtransport\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     94\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest_headers\u001b[49m\n\u001b[32m     95\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     96\u001b[39m \u001b[38;5;28mself\u001b[39m._set_rate_limit(data.headers)\n\u001b[32m     97\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\melis\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\openaq\\_sync\\transport.py:28\u001b[39m, in \u001b[36mTransport.send_request\u001b[39m\u001b[34m(self, method, url, params, headers)\u001b[39m\n\u001b[32m     21\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Sends an HTTP request using the provided method, URL, parameters, and headers.\"\"\"\u001b[39;00m\n\u001b[32m     22\u001b[39m request = httpx.Request(\n\u001b[32m     23\u001b[39m     method=method,\n\u001b[32m     24\u001b[39m     url=url,\n\u001b[32m     25\u001b[39m     params=params,\n\u001b[32m     26\u001b[39m     headers=headers,\n\u001b[32m     27\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m res = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m check_response(res)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\melis\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\httpx\\_client.py:928\u001b[39m, in \u001b[36mClient.send\u001b[39m\u001b[34m(self, request, stream, auth, follow_redirects)\u001b[39m\n\u001b[32m    926\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    927\u001b[39m     response.close()\n\u001b[32m--> \u001b[39m\u001b[32m928\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\melis\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\httpx\\_client.py:922\u001b[39m, in \u001b[36mClient.send\u001b[39m\u001b[34m(self, request, stream, auth, follow_redirects)\u001b[39m\n\u001b[32m    920\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    921\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n\u001b[32m--> \u001b[39m\u001b[32m922\u001b[39m         \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    924\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n\u001b[32m    926\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\melis\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\httpx\\_models.py:881\u001b[39m, in \u001b[36mResponse.read\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    877\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    878\u001b[39m \u001b[33;03mRead and return the response content.\u001b[39;00m\n\u001b[32m    879\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    880\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m_content\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m881\u001b[39m     \u001b[38;5;28mself\u001b[39m._content = \u001b[33;43mb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miter_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    882\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._content\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\melis\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\httpx\\_models.py:897\u001b[39m, in \u001b[36mResponse.iter_bytes\u001b[39m\u001b[34m(self, chunk_size)\u001b[39m\n\u001b[32m    895\u001b[39m chunker = ByteChunker(chunk_size=chunk_size)\n\u001b[32m    896\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request=\u001b[38;5;28mself\u001b[39m._request):\n\u001b[32m--> \u001b[39m\u001b[32m897\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mraw_bytes\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miter_raw\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    898\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecoded\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_bytes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    899\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunker\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdecoded\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\melis\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\httpx\\_models.py:951\u001b[39m, in \u001b[36mResponse.iter_raw\u001b[39m\u001b[34m(self, chunk_size)\u001b[39m\n\u001b[32m    948\u001b[39m chunker = ByteChunker(chunk_size=chunk_size)\n\u001b[32m    950\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request=\u001b[38;5;28mself\u001b[39m._request):\n\u001b[32m--> \u001b[39m\u001b[32m951\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mraw_stream_bytes\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    952\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_num_bytes_downloaded\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mraw_stream_bytes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    953\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunker\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_stream_bytes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\melis\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\httpx\\_client.py:153\u001b[39m, in \u001b[36mBoundSyncStream.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    152\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> typing.Iterator[\u001b[38;5;28mbytes\u001b[39m]:\n\u001b[32m--> \u001b[39m\u001b[32m153\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_stream\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    154\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\melis\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\httpx\\_transports\\default.py:127\u001b[39m, in \u001b[36mResponseStream.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    125\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> typing.Iterator[\u001b[38;5;28mbytes\u001b[39m]:\n\u001b[32m    126\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[32m--> \u001b[39m\u001b[32m127\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpart\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_httpcore_stream\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    128\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpart\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\melis\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\httpcore\\_sync\\connection_pool.py:407\u001b[39m, in \u001b[36mPoolByteStream.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    405\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    406\u001b[39m     \u001b[38;5;28mself\u001b[39m.close()\n\u001b[32m--> \u001b[39m\u001b[32m407\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\melis\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\httpcore\\_sync\\connection_pool.py:403\u001b[39m, in \u001b[36mPoolByteStream.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    401\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> typing.Iterator[\u001b[38;5;28mbytes\u001b[39m]:\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m403\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpart\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_stream\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    404\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpart\u001b[49m\n\u001b[32m    405\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\melis\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\httpcore\\_sync\\http11.py:342\u001b[39m, in \u001b[36mHTTP11ConnectionByteStream.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    340\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m ShieldCancellation():\n\u001b[32m    341\u001b[39m     \u001b[38;5;28mself\u001b[39m.close()\n\u001b[32m--> \u001b[39m\u001b[32m342\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\melis\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\httpcore\\_sync\\http11.py:334\u001b[39m, in \u001b[36mHTTP11ConnectionByteStream.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    332\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    333\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[33m\"\u001b[39m\u001b[33mreceive_response_body\u001b[39m\u001b[33m\"\u001b[39m, logger, \u001b[38;5;28mself\u001b[39m._request, kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m334\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_connection\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_receive_response_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    335\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\n\u001b[32m    336\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    337\u001b[39m     \u001b[38;5;66;03m# If we get an exception while streaming the response,\u001b[39;00m\n\u001b[32m    338\u001b[39m     \u001b[38;5;66;03m# we want to close the response (and possibly the connection)\u001b[39;00m\n\u001b[32m    339\u001b[39m     \u001b[38;5;66;03m# before raising that exception.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\melis\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\httpcore\\_sync\\http11.py:203\u001b[39m, in \u001b[36mHTTP11Connection._receive_response_body\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    200\u001b[39m timeout = timeouts.get(\u001b[33m\"\u001b[39m\u001b[33mread\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    202\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m203\u001b[39m     event = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    204\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11.Data):\n\u001b[32m    205\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mbytes\u001b[39m(event.data)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\melis\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\httpcore\\_sync\\http11.py:217\u001b[39m, in \u001b[36mHTTP11Connection._receive_event\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    214\u001b[39m     event = \u001b[38;5;28mself\u001b[39m._h11_state.next_event()\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11.NEED_DATA:\n\u001b[32m--> \u001b[39m\u001b[32m217\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_network_stream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    218\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    227\u001b[39m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[32m    228\u001b[39m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[32m    229\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m data == \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._h11_state.their_state == h11.SEND_RESPONSE:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\melis\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\httpcore\\_backends\\sync.py:128\u001b[39m, in \u001b[36mSyncStream.read\u001b[39m\u001b[34m(self, max_bytes, timeout)\u001b[39m\n\u001b[32m    126\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[32m    127\u001b[39m     \u001b[38;5;28mself\u001b[39m._sock.settimeout(timeout)\n\u001b[32m--> \u001b[39m\u001b[32m128\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\melis\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\ssl.py:1232\u001b[39m, in \u001b[36mSSLSocket.recv\u001b[39m\u001b[34m(self, buflen, flags)\u001b[39m\n\u001b[32m   1228\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m flags != \u001b[32m0\u001b[39m:\n\u001b[32m   1229\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1230\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m   1231\u001b[39m             \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1232\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuflen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1233\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1234\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().recv(buflen, flags)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\melis\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\ssl.py:1105\u001b[39m, in \u001b[36mSSLSocket.read\u001b[39m\u001b[34m(self, len, buffer)\u001b[39m\n\u001b[32m   1103\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sslobj.read(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[32m   1104\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1105\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1106\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m SSLError \u001b[38;5;28;01mas\u001b[39;00m x:\n\u001b[32m   1107\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m x.args[\u001b[32m0\u001b[39m] == SSL_ERROR_EOF \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.suppress_ragged_eofs:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# BLOK1: APİDEN VERİ ÇEKME \n",
    "import pandas as pd\n",
    "from openaq import OpenAQ\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "API_KEY = \"beb87bdeb247d901be44e59bd044aa34556b5c4752592b5a2cd9da243a25a466\"\n",
    "BBOX_AU = \"112.552738,-39.144150,153.685550,-11.567325\" \n",
    "COUNTRY_CODE = 'AU'\n",
    "RAW_DATA_FILE = 'openaq_raw_data_au.csv' # Dosya adı değişti sadece\n",
    "client = OpenAQ(api_key=API_KEY)\n",
    "\n",
    "def get_sensor_ids(bbox, client, country_code):\n",
    "    all_sensor_ids, sensor_country_map = [], {}\n",
    "    page = 1\n",
    "    print(f\"{country_code} bbox {bbox} içindeki sensörler çekiliyor...\")\n",
    "    while True:\n",
    "        try:\n",
    "            resp = client.locations.list(bbox=bbox, limit=1000, page=page)\n",
    "            if not resp.results: break\n",
    "            for loc in resp.results:\n",
    "                if hasattr(loc, 'sensors') and loc.sensors:\n",
    "                    for sensor in loc.sensors:\n",
    "                        sensor_id = getattr(sensor, 'id', None)\n",
    "                        if sensor_id:\n",
    "                            all_sensor_ids.append(sensor_id)\n",
    "                            sensor_country_map[sensor_id] = getattr(loc.country, 'code', country_code)\n",
    "            print(f\"Sayfa {page} çekildi, {len(resp.results)} konum eklendi\")\n",
    "            page += 1; time.sleep(0.2)\n",
    "        except Exception as e:\n",
    "            print(f\"Hata (Sayfa {page}): {e}. 5 saniye bekleniyor\"); time.sleep(5)\n",
    "            continue\n",
    "    return list(set(all_sensor_ids)), sensor_country_map\n",
    "\n",
    "def get_daily_by_sid(sids, baslangic, end, sensor_map, sleep_time=0.3):\n",
    "    all_data = []\n",
    "    print(f\"\\nToplam {len(sids)} sensör için GÜNLÜK veri çekiliyor...\")\n",
    "    for sid in tqdm(sids, desc=\"Sensör Verileri Çekiliyor\"):\n",
    "        page = 1\n",
    "        while True:\n",
    "            try:\n",
    "                resp = client.measurements.list(sensors_id=sid, data=\"days\", datetime_from=baslangic, datetime_to=end, limit=1000, page=page)\n",
    "                if not resp.results: break\n",
    "                for res in resp.results:\n",
    "                    all_data.append({\n",
    "                        \"from_date\": res.period.datetime_from.utc,\n",
    "                        \"name\": res.parameter.name,\n",
    "                        \"value\": res.value,\n",
    "                        \"unit\": res.parameter.units,\n",
    "                        \"country\": sensor_map.get(sid, 'Unknown')\n",
    "                    })\n",
    "                page += 1; time.sleep(sleep_time)\n",
    "            except Exception as e:\n",
    "                print(f\"\\nSensör {sid} için hata (Sayfa {page}): {e}. Bekleniyor...\")\n",
    "                try:\n",
    "                    wait_time = int(str(e).split('resets in ')[1].split(' ')[0]) + 1\n",
    "                    print(f\"{wait_time} saniye bekleniyor...\"); time.sleep(wait_time)\n",
    "                except:\n",
    "                    time.sleep(10)\n",
    "                continue\n",
    "    return pd.DataFrame(all_data)\n",
    "\n",
    "bitis = datetime.now()\n",
    "baslangic_date = bitis - timedelta(days=365 * 7)\n",
    "baslangic_date_str = baslangic_date.strftime(\"%Y-%m-%d\")\n",
    "bitis_str = bitis.strftime(\"%Y-%m-%d\")\n",
    "print(f\"Veri çekme aralığı: {baslangic_date_str} - {bitis_str}\")\n",
    "\n",
    "sensor_ids, sensor_country_map = get_sensor_ids(BBOX_AU, client, COUNTRY_CODE)\n",
    "if sensor_ids:\n",
    "    raw_df = get_daily_by_sid(sensor_ids, baslangic_date_str, bitis_str, sensor_country_map)\n",
    "    if not raw_df.empty:\n",
    "        raw_df.to_csv(RAW_DATA_FILE, index=False)\n",
    "        print(f\"\\nİşlenmemiş ham veri başarıyla '{RAW_DATA_FILE}' dosyasına kaydedildi\")\n",
    "        print(f\"Toplam {len(raw_df)} satır ham veri çekildi\")\n",
    "    else:\n",
    "        print(\"API'den veri çekilemedi\")\n",
    "else:\n",
    "    print(\"Belirtilen alanda sensör bulunamadı\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93fca42a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'openaq_raw_data_au.csv' dosyasından ham veri okunuyor...\n",
      "\n",
      "Birim dönüşümü başlıyor...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Birimler Dönüştürülüyor: 100%|██████████| 653341/653341 [00:16<00:00, 40319.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Veri işleme ve pivotlama başlıyor...\n",
      "\n",
      "İşlenmiş veri 'au_air_quality_processed.csv' dosyasına kaydedildi\n",
      "İşlenmiş verinin ilk 5 satırı:\n",
      "                  from_date          co  no2   o3  pm1  pm10  pm25  \\\n",
      "0 2016-01-27 13:00:00+00:00         NaN  NaN  0.0  NaN   8.0   NaN   \n",
      "1 2016-02-07 13:00:00+00:00         NaN  NaN  0.0  NaN  13.0   NaN   \n",
      "2 2016-02-08 13:00:00+00:00         NaN  NaN  0.0  NaN  18.0   NaN   \n",
      "3 2016-02-15 13:00:00+00:00  114.560327  NaN  NaN  NaN   NaN   NaN   \n",
      "4 2016-03-09 13:00:00+00:00         NaN  NaN  0.0  NaN  18.0  10.0   \n",
      "\n",
      "   relativehumidity  so2  temperature  um003  \n",
      "0               NaN  NaN          NaN    NaN  \n",
      "1               NaN  NaN          NaN    NaN  \n",
      "2               NaN  NaN          NaN    NaN  \n",
      "3               NaN  NaN          NaN    NaN  \n",
      "4               NaN  NaN          NaN    NaN  \n"
     ]
    }
   ],
   "source": [
    "# BLOK2: VERİ ÖN İŞLEME \n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "RAW_DATA_FILE = 'openaq_raw_data_au.csv'\n",
    "PROCESSED_FILE_PATH = 'au_air_quality_processed.csv'\n",
    "COUNTRY_CODE = 'AU'\n",
    "\n",
    "def process_data(file_path, country_code):\n",
    "    print(f\"'{file_path}' dosyasından ham veri okunuyor...\")\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Birim dönüştürme (µg/m³)\n",
    "    print(\"\\nBirim dönüşümü başlıyor...\")\n",
    "    MOLAR_MASSES = {'co': 28.01, 'no2': 46.01, 'o3': 48.00, 'so2': 64.07}\n",
    "    MOLAR_VOLUME = 24.45\n",
    "    converted_values = []\n",
    "    for index, row in tqdm(df.iterrows(), total=df.shape[0], desc=\"Birimler Dönüştürülüyor\"):\n",
    "        param, unit, value = str(row['name']).lower(), str(row['unit']).lower(), row['value']\n",
    "        new_value = None\n",
    "        if pd.notna(value) and value >= 0:\n",
    "            if unit == 'µg/m³': new_value = value\n",
    "            else:\n",
    "                molar_mass = MOLAR_MASSES.get(param)\n",
    "                if molar_mass is not None:\n",
    "                    if unit == 'ppm': new_value = (value * molar_mass * 1000) / MOLAR_VOLUME\n",
    "                    elif unit == 'ppb': new_value = (value * molar_mass) / MOLAR_VOLUME\n",
    "                    else: new_value = value\n",
    "                else: new_value = value\n",
    "        converted_values.append(new_value)\n",
    "    df['value_converted'] = converted_values\n",
    "    \n",
    "    # Pivotlama\n",
    "    print(\"\\nVeri işleme ve pivotlama başlıyor...\")\n",
    "    df['from_date'] = pd.to_datetime(df['from_date'], errors='coerce')\n",
    "    df.dropna(subset=['from_date', 'value_converted'], inplace=True)\n",
    "    df_filtered = df[df['country'] == country_code].copy()\n",
    "    \n",
    "    df_pivot = df_filtered.pivot_table(index='from_date', columns='name', values='value_converted', aggfunc='mean').reset_index()\n",
    "    df_pivot.columns.name = None\n",
    "    df_pivot.sort_values(by='from_date', ascending=True, inplace=True)\n",
    "    \n",
    "    return df_pivot\n",
    "\n",
    "try:\n",
    "    processed_df = process_data(RAW_DATA_FILE, COUNTRY_CODE)\n",
    "    processed_df.to_csv(PROCESSED_FILE_PATH, index=False)\n",
    "    print(f\"\\nİşlenmiş veri '{PROCESSED_FILE_PATH}' dosyasına kaydedildi\")\n",
    "    print(\"İşlenmiş verinin ilk 5 satırı:\")\n",
    "    print(processed_df.head())\n",
    "except FileNotFoundError:\n",
    "    print(f\"Hata: '{RAW_DATA_FILE}' bulunamadı\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6322ba65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'au_air_quality_processed.csv' dosyasından veri okunuyor...\n",
      "Veri başarıyla yüklendi. Boyut: (6599, 10)\n",
      "\n",
      "Eksik veri yönetimi başlıyor...\n",
      "Eksik veri yönetimi tamamlandı.\n",
      "\n",
      "Aşırı aykırı değerler %99.9 persentil ile kırpılıyor...\n",
      "  'co' sütunu, üst sınır '1147696.27' ile kırpıldı.\n",
      "  'no2' sütunu, üst sınır '17511.96' ile kırpıldı.\n",
      "  'o3' sütunu, üst sınır '569.25' ile kırpıldı.\n",
      "  'pm1' sütunu, üst sınır '81.70' ile kırpıldı.\n",
      "  'pm10' sütunu, üst sınır '99.39' ile kırpıldı.\n",
      "  'pm25' sütunu, üst sınır '72.19' ile kırpıldı.\n",
      "  'relativehumidity' sütunu, üst sınır '75.80' ile kırpıldı.\n",
      "  'so2' sütunu, üst sınır '1861.29' ile kırpıldı.\n",
      "  'temperature' sütunu, üst sınır '32.94' ile kırpıldı.\n",
      "  'um003' sütunu, üst sınır '3599.09' ile kırpıldı.\n",
      "\n",
      "Logaritmik dönüşüm uygulanıyor...\n",
      "\n",
      "Öznitelik mühendisliği başlıyor...\n",
      "Öznitelik mühendisliği tamamlandı.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\melis\\AppData\\Local\\Temp\\ipykernel_27848\\4107817557.py:26: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df.fillna(method='ffill', inplace=True); df.fillna(method='bfill', inplace=True)\n",
      "C:\\Users\\melis\\AppData\\Local\\Temp\\ipykernel_27848\\4107817557.py:46: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df.fillna(method='bfill', inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Temizlenmiş veri 'au_air_quality_engineered.csv' dosyasına kaydedildi.\n"
     ]
    }
   ],
   "source": [
    "# BLOK3: FEATURE ENGİNEERİNG\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "PROCESSED_FILE_PATH = 'au_air_quality_processed.csv'\n",
    "ENGINEERED_FILE_PATH = 'au_air_quality_engineered.csv'\n",
    "\n",
    "print(f\"'{PROCESSED_FILE_PATH}' dosyasından veri okunuyor...\")\n",
    "try:\n",
    "    df = pd.read_csv(PROCESSED_FILE_PATH, parse_dates=['from_date'])\n",
    "    df.set_index('from_date', inplace=True)\n",
    "    print(f\"Veri başarıyla yüklendi. Boyut: {df.shape}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Hata: '{PROCESSED_FILE_PATH}' bulunamadı.\")\n",
    "    exit()\n",
    "\n",
    "df.sort_index(inplace=True)\n",
    "\n",
    "# Eksik veri interpolationu\n",
    "print(\"\\nEksik veri yönetimi başlıyor...\")\n",
    "pollutant_cols = [col for col in df.columns if df[col].dtype in ['float64', 'int64']]\n",
    "# Ülke sütunu çıkarıldı\n",
    "if 'country' in pollutant_cols: pollutant_cols.remove('country')\n",
    "\n",
    "df[pollutant_cols] = df[pollutant_cols].interpolate(method='time', limit_direction='both')\n",
    "df.fillna(method='ffill', inplace=True); df.fillna(method='bfill', inplace=True)\n",
    "print(\"Eksik veri yönetimi tamamlandı.\")\n",
    "\n",
    "# Aşırı değerleri kırpma\n",
    "print(\"\\nAşırı aykırı değerler %99.9 persentil ile kırpılıyor...\")\n",
    "for col in pollutant_cols:\n",
    "    upper_limit = df[col].quantile(0.999)\n",
    "    df[col] = df[col].clip(upper=upper_limit)\n",
    "    print(f\"  '{col}' sütunu, üst sınır '{upper_limit:.2f}' ile kırpıldı.\")\n",
    "\n",
    "# Logaritmik dönüşüm\n",
    "print(\"\\nLogaritmik dönüşüm uygulanıyor...\")\n",
    "for col in pollutant_cols:\n",
    "    df[col] = np.log1p(df[col])\n",
    "\n",
    "print(\"\\nÖznitelik mühendisliği başlıyor...\")\n",
    "df['year'] = df.index.year; df['month'] = df.index.month; df['day_of_week'] = df.index.dayofweek\n",
    "for pollutant in pollutant_cols:\n",
    "    for lag in [1, 3, 7]: df[f'{pollutant}_lag_{lag}d'] = df[pollutant].shift(lag)\n",
    "    for window in [3, 7]: df[f'{pollutant}_roll_mean_{window}d'] = df[pollutant].rolling(window, closed='left').mean()\n",
    "df.fillna(method='bfill', inplace=True)\n",
    "print(\"Öznitelik mühendisliği tamamlandı.\")\n",
    "\n",
    "df.to_csv(ENGINEERED_FILE_PATH, index=True)\n",
    "print(f\"\\nTemizlenmiş veri '{ENGINEERED_FILE_PATH}' dosyasına kaydedildi.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1d07da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'au_air_quality_engineered.csv' yüklendi. Boyut: (6599, 63)\n",
      "\n",
      ">>> AU: XGBOOST - CO modeli eğitiliyor...\n",
      "-> CO için XGBOOST modeli eğitildi ve kaydedildi.\n",
      "\n",
      ">>> AU: XGBOOST - NO2 modeli eğitiliyor...\n",
      "-> NO2 için XGBOOST modeli eğitildi ve kaydedildi.\n",
      "\n",
      ">>> AU: XGBOOST - O3 modeli eğitiliyor...\n",
      "-> O3 için XGBOOST modeli eğitildi ve kaydedildi.\n",
      "\n",
      ">>> AU: XGBOOST - PM10 modeli eğitiliyor...\n",
      "-> PM10 için XGBOOST modeli eğitildi ve kaydedildi.\n",
      "\n",
      ">>> AU: XGBOOST - PM25 modeli eğitiliyor...\n",
      "-> PM25 için XGBOOST modeli eğitildi ve kaydedildi.\n",
      "\n",
      ">>> AU: XGBOOST - SO2 modeli eğitiliyor...\n",
      "-> SO2 için XGBOOST modeli eğitildi ve kaydedildi.\n",
      "\n",
      ">>> AU: RANDOMFOREST - CO modeli eğitiliyor...\n",
      "-> CO için RANDOMFOREST modeli eğitildi ve kaydedildi.\n",
      "\n",
      ">>> AU: RANDOMFOREST - NO2 modeli eğitiliyor...\n",
      "-> NO2 için RANDOMFOREST modeli eğitildi ve kaydedildi.\n",
      "\n",
      ">>> AU: RANDOMFOREST - O3 modeli eğitiliyor...\n",
      "-> O3 için RANDOMFOREST modeli eğitildi ve kaydedildi.\n",
      "\n",
      ">>> AU: RANDOMFOREST - PM10 modeli eğitiliyor...\n",
      "-> PM10 için RANDOMFOREST modeli eğitildi ve kaydedildi.\n",
      "\n",
      ">>> AU: RANDOMFOREST - PM25 modeli eğitiliyor...\n",
      "-> PM25 için RANDOMFOREST modeli eğitildi ve kaydedildi.\n",
      "\n",
      ">>> AU: RANDOMFOREST - SO2 modeli eğitiliyor...\n",
      "-> SO2 için RANDOMFOREST modeli eğitildi ve kaydedildi.\n",
      "\n",
      ">>> AU: MLP - CO modeli eğitiliyor...\n",
      "-> CO için MLP modeli eğitildi ve kaydedildi.\n",
      "\n",
      ">>> AU: MLP - NO2 modeli eğitiliyor...\n",
      "-> NO2 için MLP modeli eğitildi ve kaydedildi.\n",
      "\n",
      ">>> AU: MLP - O3 modeli eğitiliyor...\n",
      "-> O3 için MLP modeli eğitildi ve kaydedildi.\n",
      "\n",
      ">>> AU: MLP - PM10 modeli eğitiliyor...\n",
      "-> PM10 için MLP modeli eğitildi ve kaydedildi.\n",
      "\n",
      ">>> AU: MLP - PM25 modeli eğitiliyor...\n",
      "-> PM25 için MLP modeli eğitildi ve kaydedildi.\n",
      "\n",
      ">>> AU: MLP - SO2 modeli eğitiliyor...\n",
      "-> SO2 için MLP modeli eğitildi ve kaydedildi.\n",
      "\n",
      ">>> AU: KNN - CO modeli eğitiliyor...\n",
      "-> CO için KNN modeli eğitildi ve kaydedildi.\n",
      "\n",
      ">>> AU: KNN - NO2 modeli eğitiliyor...\n",
      "-> NO2 için KNN modeli eğitildi ve kaydedildi.\n",
      "\n",
      ">>> AU: KNN - O3 modeli eğitiliyor...\n",
      "-> O3 için KNN modeli eğitildi ve kaydedildi.\n",
      "\n",
      ">>> AU: KNN - PM10 modeli eğitiliyor...\n",
      "-> PM10 için KNN modeli eğitildi ve kaydedildi.\n",
      "\n",
      ">>> AU: KNN - PM25 modeli eğitiliyor...\n",
      "-> PM25 için KNN modeli eğitildi ve kaydedildi.\n",
      "\n",
      ">>> AU: KNN - SO2 modeli eğitiliyor...\n",
      "-> SO2 için KNN modeli eğitildi ve kaydedildi.\n"
     ]
    }
   ],
   "source": [
    "# BLOK4: TRAİNİNG\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, TimeSeriesSplit\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "import joblib\n",
    "import warnings\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# --- AYARLAR (Bu satırı her ülke notebook'unda güncelleyin) ---\n",
    "COUNTRY_CODE = 'au' \n",
    "country_code='au'\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "ENGINEERED_FILE_PATH = f'{COUNTRY_CODE}_air_quality_engineered.csv'\n",
    "TARGET_POLLUTANTS = ['co', 'no2', 'o3', 'pm10', 'pm25', 'so2']\n",
    "FORECAST_HORIZON = 1\n",
    "\n",
    "# Veriyi Yükle\n",
    "df_engineered = pd.read_csv(ENGINEERED_FILE_PATH, index_col='from_date', parse_dates=True)\n",
    "print(f\"'{ENGINEERED_FILE_PATH}' yüklendi. Boyut: {df_engineered.shape}\")\n",
    "\n",
    "# Model Tanımları\n",
    "models = {\n",
    "    \"xgboost\": {\"estimator\": xgb.XGBRegressor(random_state=42), \"params\": {'n_estimators': [100, 300], 'max_depth': [5, 7]}},\n",
    "    \"randomforest\": {\"estimator\": RandomForestRegressor(random_state=42), \"params\": {'n_estimators': [100, 200], 'max_depth': [10, 20]}},\n",
    "    \"mlp\": {\"estimator\": MLPRegressor(random_state=42, max_iter=500, early_stopping=True), \"params\": {'hidden_layer_sizes': [(64, 32)], 'alpha': [0.001, 0.05]}},\n",
    "    \"knn\": {\"estimator\": KNeighborsRegressor(), \"params\": {'n_neighbors': [7, 15], 'weights': ['uniform', 'distance']}}\n",
    "}\n",
    "\n",
    "available_targets = [p for p in TARGET_POLLUTANTS if p in df_engineered.columns]\n",
    "\n",
    "for model_name, model_info in models.items():\n",
    "    for target in available_targets:\n",
    "        print(f\"\\n>>> {country_code.upper()}: {model_name.upper()} - {target.upper()} modeli eğitiliyor...\")\n",
    "        \n",
    "        # 1. Veri Hazırlama\n",
    "        features_to_use = [col for col in df_engineered.columns if col not in TARGET_POLLUTANTS + ['country']]\n",
    "        X = df_engineered[features_to_use].copy()\n",
    "        y = df_engineered[[target]].shift(-FORECAST_HORIZON)\n",
    "        X, y = X.iloc[:-FORECAST_HORIZON], y.iloc[:-FORECAST_HORIZON]\n",
    "        X.dropna(axis=1, how='all', inplace=True); X.fillna(0, inplace=True)\n",
    "        \n",
    "        X_train_full, X_test, y_train_full, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "        \n",
    "        # 2. Test için nesneleri oluştur ve kaydet\n",
    "        x_scaler = RobustScaler().fit(X_train_full)\n",
    "        y_scaler = RobustScaler().fit(y_train_full)\n",
    "        k_val = min(20 if model_name == 'knn' else 35, X_train_full.shape[1])\n",
    "        X_train_s = pd.DataFrame(x_scaler.transform(X_train_full), columns=X_train_full.columns)\n",
    "        selector = SelectKBest(score_func=f_regression, k=k_val).fit(X_train_s, y_train_full.values.ravel())\n",
    "        \n",
    "        joblib.dump(x_scaler, f'x_scaler_{model_name}_{target}_{country_code}.pkl')\n",
    "        joblib.dump(y_scaler, f'y_scaler_{model_name}_{target}_{country_code}.pkl')\n",
    "        joblib.dump(selector, f'selector_{model_name}_{target}_{country_code}.pkl')\n",
    "        X_test.to_csv(f'X_test_{target}_{country_code}.csv')\n",
    "        y_test.to_csv(f'y_test_{target}_{country_code}.csv')\n",
    "\n",
    "        # 3. Hiperparametre Optimizasyonu\n",
    "        X_train_hp_f = selector.transform(X_train_s)\n",
    "        y_train_hp_s = y_scaler.transform(y_train_full)\n",
    "        \n",
    "        tscv = TimeSeriesSplit(n_splits=3)\n",
    "        random_search = RandomizedSearchCV(\n",
    "            estimator=model_info[\"estimator\"], param_distributions=model_info[\"params\"],\n",
    "            n_iter=4, cv=tscv, scoring='neg_root_mean_squared_error', random_state=42, n_jobs=-1\n",
    "        )\n",
    "        random_search.fit(X_train_hp_f, y_train_hp_s.ravel())\n",
    "        best_params = random_search.best_params_\n",
    "        \n",
    "        # 4. Final Modeli Tüm Eğitim Verisiyle Eğit ve Kaydet\n",
    "        final_model = model_info[\"estimator\"].set_params(**best_params)\n",
    "        final_model.fit(X_train_hp_f, y_train_hp_s.ravel())\n",
    "        joblib.dump(final_model, f'model_{model_name}_{target}_{country_code}.pkl')\n",
    "        \n",
    "        print(f\"-> {target.upper()} için {model_name.upper()} modeli eğitildi ve kaydedildi.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
