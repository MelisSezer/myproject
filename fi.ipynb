{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0d3fb2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Veri çekme aralığı: 2018-07-13 - 2025-07-11\n",
      "FI bbox 21.164067,59.948690,31.359379,69.915364 içindeki sensörler çekiliyor...\n",
      "Sayfa 1 çekildi, 89 konum eklendi\n",
      "\n",
      "Toplam 198 sensör için GÜNLÜK veri çekiliyor...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sensör Verileri Çekiliyor:   2%|▏         | 3/198 [00:05<06:28,  1.99s/it]HTTP 429 - {\"detail\":\"Too many requests\"}\n",
      "NoneType: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sensör 11275 için hata (Sayfa 4): {\"detail\":\"Too many requests\"}. Bekleniyor...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HTTP 429 - {\"detail\":\"Too many requests\"}\n",
      "NoneType: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sensör 11275 için hata (Sayfa 4): {\"detail\":\"Too many requests\"}. Bekleniyor...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HTTP 429 - {\"detail\":\"Too many requests\"}\n",
      "NoneType: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sensör 11275 için hata (Sayfa 4): {\"detail\":\"Too many requests\"}. Bekleniyor...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HTTP 429 - {\"detail\":\"Too many requests\"}\n",
      "NoneType: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sensör 11275 için hata (Sayfa 4): {\"detail\":\"Too many requests\"}. Bekleniyor...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HTTP 429 - {\"detail\":\"Too many requests\"}\n",
      "NoneType: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sensör 11275 için hata (Sayfa 4): {\"detail\":\"Too many requests\"}. Bekleniyor...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sensör Verileri Çekiliyor:   4%|▎         | 7/198 [01:20<31:11,  9.80s/it]  HTTP 429 - {\"detail\":\"Too many requests\"}\n",
      "NoneType: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sensör 28188 için hata (Sayfa 4): {\"detail\":\"Too many requests\"}. Bekleniyor...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HTTP 429 - {\"detail\":\"Too many requests\"}\n",
      "NoneType: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sensör 28188 için hata (Sayfa 4): {\"detail\":\"Too many requests\"}. Bekleniyor...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HTTP 429 - {\"detail\":\"Too many requests\"}\n",
      "NoneType: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sensör 28188 için hata (Sayfa 4): {\"detail\":\"Too many requests\"}. Bekleniyor...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sensör Verileri Çekiliyor:   7%|▋         | 13/198 [02:23<18:22,  5.96s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sensör 26679 için hata (Sayfa 1): Rate limit exceeded. Limit resets in 36 seconds. Bekleniyor...\n",
      "37 saniye bekleniyor...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sensör Verileri Çekiliyor:  12%|█▏        | 24/198 [03:45<08:11,  2.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sensör 11348 için hata (Sayfa 2): Rate limit exceeded. Limit resets in 15 seconds. Bekleniyor...\n",
      "16 saniye bekleniyor...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sensör Verileri Çekiliyor:  17%|█▋        | 33/198 [04:43<16:09,  5.88s/it]HTTP 429 - {\"detail\":\"Too many requests\"}\n",
      "NoneType: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sensör 8613483 için hata (Sayfa 2): {\"detail\":\"Too many requests\"}. Bekleniyor...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HTTP 429 - {\"detail\":\"Too many requests\"}\n",
      "NoneType: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sensör 8613483 için hata (Sayfa 2): {\"detail\":\"Too many requests\"}. Bekleniyor...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sensör Verileri Çekiliyor:  25%|██▍       | 49/198 [06:44<14:46,  5.95s/it]HTTP 429 - {\"detail\":\"Too many requests\"}\n",
      "NoneType: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sensör 11401 için hata (Sayfa 4): {\"detail\":\"Too many requests\"}. Bekleniyor...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sensör Verileri Çekiliyor:  29%|██▉       | 58/198 [07:56<17:29,  7.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sensör 12178079 için hata (Sayfa 1): Rate limit exceeded. Limit resets in 7 seconds. Bekleniyor...\n",
      "8 saniye bekleniyor...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sensör Verileri Çekiliyor:  38%|███▊      | 75/198 [09:52<08:41,  4.24s/it]HTTP 429 - {\"detail\":\"Too many requests\"}\n",
      "NoneType: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sensör 6321 için hata (Sayfa 2): {\"detail\":\"Too many requests\"}. Bekleniyor...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sensör Verileri Çekiliyor:  42%|████▏     | 84/198 [10:39<07:29,  3.94s/it]HTTP 429 - {\"detail\":\"Too many requests\"}\n",
      "NoneType: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sensör 6349 için hata (Sayfa 3): {\"detail\":\"Too many requests\"}. Bekleniyor...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HTTP 429 - {\"detail\":\"Too many requests\"}\n",
      "NoneType: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sensör 6349 için hata (Sayfa 3): {\"detail\":\"Too many requests\"}. Bekleniyor...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sensör Verileri Çekiliyor:  52%|█████▏    | 102/198 [12:49<07:36,  4.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sensör 6381 için hata (Sayfa 2): Rate limit exceeded. Limit resets in 8 seconds. Bekleniyor...\n",
      "9 saniye bekleniyor...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sensör Verileri Çekiliyor:  55%|█████▍    | 108/198 [13:41<09:39,  6.44s/it]HTTP 429 - {\"detail\":\"Too many requests\"}\n",
      "NoneType: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sensör 8613623 için hata (Sayfa 1): {\"detail\":\"Too many requests\"}. Bekleniyor...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HTTP 429 - {\"detail\":\"Too many requests\"}\n",
      "NoneType: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sensör 8613623 için hata (Sayfa 1): {\"detail\":\"Too many requests\"}. Bekleniyor...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sensör Verileri Çekiliyor:  57%|█████▋    | 112/198 [14:34<15:14, 10.63s/it]HTTP 429 - {\"detail\":\"Too many requests\"}\n",
      "NoneType: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sensör 6403 için hata (Sayfa 1): {\"detail\":\"Too many requests\"}. Bekleniyor...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HTTP 429 - {\"detail\":\"Too many requests\"}\n",
      "NoneType: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sensör 6403 için hata (Sayfa 1): {\"detail\":\"Too many requests\"}. Bekleniyor...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HTTP 429 - {\"detail\":\"Too many requests\"}\n",
      "NoneType: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sensör 6403 için hata (Sayfa 1): {\"detail\":\"Too many requests\"}. Bekleniyor...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sensör Verileri Çekiliyor:  60%|██████    | 119/198 [15:43<08:55,  6.77s/it]HTTP 429 - {\"detail\":\"Too many requests\"}\n",
      "NoneType: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sensör 11538 için hata (Sayfa 4): {\"detail\":\"Too many requests\"}. Bekleniyor...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sensör Verileri Çekiliyor:  65%|██████▍   | 128/198 [16:41<07:31,  6.45s/it]HTTP 429 - {\"detail\":\"Too many requests\"}\n",
      "NoneType: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sensör 11552 için hata (Sayfa 2): {\"detail\":\"Too many requests\"}. Bekleniyor...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HTTP 429 - {\"detail\":\"Too many requests\"}\n",
      "NoneType: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sensör 11552 için hata (Sayfa 2): {\"detail\":\"Too many requests\"}. Bekleniyor...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sensör Verileri Çekiliyor:  68%|██████▊   | 135/198 [17:45<07:42,  7.34s/it]HTTP 429 - {\"detail\":\"Too many requests\"}\n",
      "NoneType: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sensör 11064 için hata (Sayfa 3): {\"detail\":\"Too many requests\"}. Bekleniyor...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sensör Verileri Çekiliyor:  73%|███████▎  | 145/198 [18:38<03:01,  3.43s/it]HTTP 429 - {\"detail\":\"Too many requests\"}\n",
      "NoneType: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sensör 26979 için hata (Sayfa 2): {\"detail\":\"Too many requests\"}. Bekleniyor...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HTTP 429 - {\"detail\":\"Too many requests\"}\n",
      "NoneType: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sensör 26979 için hata (Sayfa 2): {\"detail\":\"Too many requests\"}. Bekleniyor...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sensör Verileri Çekiliyor:  80%|███████▉  | 158/198 [19:45<02:45,  4.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sensör 11164 için hata (Sayfa 1): Rate limit exceeded. Limit resets in 17 seconds. Bekleniyor...\n",
      "18 saniye bekleniyor...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sensör Verileri Çekiliyor:  83%|████████▎ | 164/198 [20:46<04:01,  7.11s/it]HTTP 429 - {\"detail\":\"Too many requests\"}\n",
      "NoneType: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sensör 27555 için hata (Sayfa 2): {\"detail\":\"Too many requests\"}. Bekleniyor...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sensör Verileri Çekiliyor:  88%|████████▊ | 175/198 [21:39<01:04,  2.81s/it]HTTP 429 - {\"detail\":\"Too many requests\"}\n",
      "NoneType: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sensör 27064 için hata (Sayfa 3): {\"detail\":\"Too many requests\"}. Bekleniyor...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HTTP 429 - {\"detail\":\"Too many requests\"}\n",
      "NoneType: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sensör 27064 için hata (Sayfa 3): {\"detail\":\"Too many requests\"}. Bekleniyor...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sensör Verileri Çekiliyor:  95%|█████████▍| 188/198 [22:49<00:39,  3.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sensör 1358811 için hata (Sayfa 1): Rate limit exceeded. Limit resets in 12 seconds. Bekleniyor...\n",
      "13 saniye bekleniyor...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sensör Verileri Çekiliyor: 100%|██████████| 198/198 [23:43<00:00,  7.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "İşlenmemiş ham veri başarıyla 'openaq_raw_data_fi.csv' dosyasına kaydedildi\n",
      "Toplam 268579 satır ham veri çekildi\n"
     ]
    }
   ],
   "source": [
    "# BLOK1: APİDEN VERİ ÇEKME \n",
    "import pandas as pd\n",
    "from openaq import OpenAQ\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "API_KEY = \"beb87bdeb247d901be44e59bd044aa34556b5c4752592b5a2cd9da243a25a466\"\n",
    "BBOX_FI = \"21.164067,59.948690,31.359379,69.915364\" # Finlandiya koordinatları\n",
    "COUNTRY_CODE = 'FI'\n",
    "RAW_DATA_FILE = 'openaq_raw_data_fi.csv' # Ham verinin kaydedileceği dosya\n",
    "\n",
    "client = OpenAQ(api_key=API_KEY)\n",
    "\n",
    "def get_all_sensor_ids_in_bbox(bbox, client, country_code):\n",
    "    all_sensor_ids, sensor_country_map = [], {}\n",
    "    page = 1\n",
    "    print(f\"{country_code} bbox {bbox} içindeki sensörler çekiliyor...\")\n",
    "    while True:\n",
    "        try:\n",
    "            resp = client.locations.list(bbox=bbox, limit=1000, page=page)\n",
    "            if not resp.results: break\n",
    "            for loc in resp.results:\n",
    "                if hasattr(loc, 'sensors') and loc.sensors:\n",
    "                    for sensor in loc.sensors:\n",
    "                        sensor_id = getattr(sensor, 'id', None)\n",
    "                        if sensor_id:\n",
    "                            all_sensor_ids.append(sensor_id)\n",
    "                            sensor_country_map[sensor_id] = getattr(loc.country, 'code', country_code)\n",
    "            print(f\"Sayfa {page} çekildi, {len(resp.results)} konum eklendi\")\n",
    "            page += 1; time.sleep(0.2)\n",
    "        except Exception as e:\n",
    "            print(f\"Hata (Sayfa {page}): {e}. 5 saniye bekleniyor.\"); time.sleep(5)\n",
    "            continue\n",
    "    return list(set(all_sensor_ids)), sensor_country_map\n",
    "\n",
    "def get_daily_by_sid(sids, start, end, sensor_map, sleep_time=0.3):\n",
    "    all_data = []\n",
    "    print(f\"\\nToplam {len(sids)} sensör için GÜNLÜK veri çekiliyor...\")\n",
    "    for sid in tqdm(sids, desc=\"Sensör Verileri Çekiliyor\"):\n",
    "        page = 1\n",
    "        while True:\n",
    "            try:\n",
    "                resp = client.measurements.list(sensors_id=sid, data=\"days\", datetime_from=start, datetime_to=end, limit=1000, page=page)\n",
    "                if not resp.results: break\n",
    "                for res in resp.results:\n",
    "                    all_data.append({\n",
    "                        \"from_date\": res.period.datetime_from.utc,\n",
    "                        \"name\": res.parameter.name,\n",
    "                        \"value\": res.value,\n",
    "                        \"unit\": res.parameter.units,\n",
    "                        \"country\": sensor_map.get(sid, 'Unknown')\n",
    "                    })\n",
    "                page += 1; time.sleep(sleep_time)\n",
    "            except Exception as e:\n",
    "                print(f\"\\nSensör {sid} için hata (Sayfa {page}): {e}. Bekleniyor...\")\n",
    "                try:\n",
    "                    wait_time = int(str(e).split('resets in ')[1].split(' ')[0]) + 1\n",
    "                    print(f\"{wait_time} saniye bekleniyor...\"); time.sleep(wait_time)\n",
    "                except:\n",
    "                    time.sleep(10)\n",
    "                continue\n",
    "    return pd.DataFrame(all_data)\n",
    "\n",
    "bitis = datetime.now()\n",
    "baslangic = bitis - timedelta(days=365 * 7)\n",
    "baslangic_str = baslangic.strftime(\"%Y-%m-%d\")\n",
    "bitis_str = bitis.strftime(\"%Y-%m-%d\")\n",
    "print(f\"Veri çekme aralığı: {baslangic_str} - {bitis_str}\")\n",
    "\n",
    "sensor_ids, sensor_country_map = get_all_sensor_ids_in_bbox(BBOX_FI, client, COUNTRY_CODE)\n",
    "if sensor_ids:\n",
    "    raw_df = get_daily_by_sid(sensor_ids, baslangic_str, bitis_str, sensor_country_map)\n",
    "    if not raw_df.empty:\n",
    "        raw_df.to_csv(RAW_DATA_FILE, index=False)\n",
    "        print(f\"\\nİşlenmemiş ham veri başarıyla '{RAW_DATA_FILE}' dosyasına kaydedildi\")\n",
    "        print(f\"Toplam {len(raw_df)} satır ham veri çekildi\")\n",
    "    else:\n",
    "        print(\"API'den veri çekilemedi\")\n",
    "else:\n",
    "    print(\"Belirtilen alanda sensör bulunamadı\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8162637c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'openaq_raw_data_fi.csv' dosyasından ham veri okunuyor...\n",
      "\n",
      "Birim dönüşümü başlıyor...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Birimler Dönüştürülüyor: 100%|██████████| 268579/268579 [00:06<00:00, 41618.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Veri işleme ve pivotlama başlıyor...\n",
      "\n",
      "İşlenmiş (logaritmasız) veri 'fi_air_quality_processed.csv' dosyasına kaydedildi\n",
      "İşlenmiş verinin ilk 5 satırı:\n",
      "                  from_date        no2         o3  pm1       pm10      pm25  \\\n",
      "0 2016-12-09 22:00:00+00:00  13.479308  65.770000  NaN  15.753214  4.704615   \n",
      "1 2016-12-10 22:00:00+00:00  12.045000  65.750000  NaN  10.063571  3.865385   \n",
      "2 2016-12-11 22:00:00+00:00  19.222154  63.310000  NaN   9.663571  4.333077   \n",
      "3 2016-12-12 22:00:00+00:00  23.652923  59.690000  NaN   6.394074  3.754615   \n",
      "4 2016-12-13 22:00:00+00:00  17.254077  56.054545  NaN   9.161429  5.101538   \n",
      "\n",
      "   relativehumidity       so2  temperature  um003  \n",
      "0               NaN  0.799433          NaN    NaN  \n",
      "1               NaN  0.887144          NaN    NaN  \n",
      "2               NaN  0.841889          NaN    NaN  \n",
      "3               NaN  0.764556          NaN    NaN  \n",
      "4               NaN  0.854444          NaN    NaN  \n"
     ]
    }
   ],
   "source": [
    "# BLOK2: VERİ ÖN İŞLEME \n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "RAW_DATA_FILE = 'openaq_raw_data_fi.csv'\n",
    "PROCESSED_FILE_PATH = 'fi_air_quality_processed.csv'\n",
    "COUNTRY_CODE = 'FI'\n",
    "\n",
    "def convert_and_process_data(file_path, country_code):\n",
    "    print(f\"'{file_path}' dosyasından ham veri okunuyor...\")\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Birim dönüştürme (µg/m³)\n",
    "    print(\"\\nBirim dönüşümü başlıyor...\")\n",
    "    MOLAR_MASSES = {'co': 28.01, 'no2': 46.01, 'o3': 48.00, 'so2': 64.07}\n",
    "    MOLAR_VOLUME = 24.45\n",
    "    converted_values = []\n",
    "    for index, row in tqdm(df.iterrows(), total=df.shape[0], desc=\"Birimler Dönüştürülüyor\"):\n",
    "        param, unit, value = str(row['name']).lower(), str(row['unit']).lower(), row['value']\n",
    "        new_value = None\n",
    "        if pd.notna(value) and value >= 0:\n",
    "            if unit == 'µg/m³': new_value = value\n",
    "            else:\n",
    "                molar_mass = MOLAR_MASSES.get(param)\n",
    "                if molar_mass is not None:\n",
    "                    if unit == 'ppm': new_value = (value * molar_mass * 1000) / MOLAR_VOLUME\n",
    "                    elif unit == 'ppb': new_value = (value * molar_mass) / MOLAR_VOLUME\n",
    "                    else: new_value = value\n",
    "                else: new_value = value\n",
    "        converted_values.append(new_value)\n",
    "    df['value_converted'] = converted_values\n",
    "    \n",
    "    # Pivotlama\n",
    "    print(\"\\nVeri işleme ve pivotlama başlıyor...\")\n",
    "    df['from_date'] = pd.to_datetime(df['from_date'], errors='coerce')\n",
    "    df.dropna(subset=['from_date', 'value_converted'], inplace=True)\n",
    "    df_filtered = df[df['country'] == country_code].copy()\n",
    "    \n",
    "    df_pivot = df_filtered.pivot_table(index='from_date', columns='name', values='value_converted', aggfunc='mean').reset_index()\n",
    "    df_pivot.columns.name = None\n",
    "    df_pivot.sort_values(by='from_date', ascending=True, inplace=True)\n",
    "    \n",
    "    return df_pivot\n",
    "\n",
    "try:\n",
    "    processed_df = convert_and_process_data(RAW_DATA_FILE, COUNTRY_CODE)\n",
    "    processed_df.to_csv(PROCESSED_FILE_PATH, index=False)\n",
    "    print(f\"\\nİşlenmiş (logaritmasız) veri '{PROCESSED_FILE_PATH}' dosyasına kaydedildi\")\n",
    "    print(\"İşlenmiş verinin ilk 5 satırı:\")\n",
    "    print(processed_df.head())\n",
    "except FileNotFoundError:\n",
    "    print(f\"Hata: '{RAW_DATA_FILE}' bulunamadı. Lütfen önce 1. hücreyi çalıştırıp veriyi indirin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be58d933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'fi_air_quality_processed.csv' dosyasından veri okunuyor...\n",
      "Veri başarıyla yüklendi. Boyut: (2886, 9)\n",
      "\n",
      "Eksik veri yönetimi başlıyor...\n",
      "Eksik veri yönetimi tamamlandı.\n",
      "\n",
      "Aşırı aykırı değerler %99.9 persentil ile kırpılıyor...\n",
      " 'no2' sütunu, üst sınır '37.94' ile kırpıldı.\n",
      " 'o3' sütunu, üst sınır '95.70' ile kırpıldı.\n",
      " 'pm1' sütunu, üst sınır '17.04' ile kırpıldı.\n",
      " 'pm10' sütunu, üst sınır '52.72' ile kırpıldı.\n",
      " 'pm25' sütunu, üst sınır '20.67' ile kırpıldı.\n",
      " 'relativehumidity' sütunu, üst sınır '69.20' ile kırpıldı.\n",
      " 'so2' sütunu, üst sınır '9.68' ile kırpıldı.\n",
      " 'temperature' sütunu, üst sınır '19.44' ile kırpıldı.\n",
      " 'um003' sütunu, üst sınır '2998.05' ile kırpıldı.\n",
      "\n",
      "Logaritmik dönüşüm uygulanıyor...\n",
      "\n",
      "Öznitelik mühendisliği başlıyor...\n",
      "Öznitelik mühendisliği tamamlandı\n",
      "\n",
      "Temizlenmiş ve öznitelik mühendisliği yapılmış veri 'fi_air_quality_engineered.csv' dosyasına kaydedildi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\melis\\AppData\\Local\\Temp\\ipykernel_26824\\3581080136.py:26: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df.fillna(method='ffill', inplace=True); df.fillna(method='bfill', inplace=True)\n",
      "C:\\Users\\melis\\AppData\\Local\\Temp\\ipykernel_26824\\3581080136.py:46: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df.fillna(method='bfill', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# BLOK3: FEATURE ENGİNEERİNG\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "PROCESSED_FILE_PATH = 'fi_air_quality_processed.csv'\n",
    "ENGINEERED_FILE_PATH = 'fi_air_quality_engineered.csv'\n",
    "\n",
    "print(f\"'{PROCESSED_FILE_PATH}' dosyasından veri okunuyor...\")\n",
    "try:\n",
    "    df = pd.read_csv(PROCESSED_FILE_PATH, parse_dates=['from_date'])\n",
    "    df.set_index('from_date', inplace=True)\n",
    "    print(f\"Veri başarıyla yüklendi. Boyut: {df.shape}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Hata: '{PROCESSED_FILE_PATH}' bulunamadı. Lütfen 2. hücreyi çalıştırdığınızdan emin olu.\")\n",
    "    exit()\n",
    "\n",
    "df.sort_index(inplace=True)\n",
    "\n",
    "# Eksik veri interpolasyonu\n",
    "print(\"\\nEksik veri yönetimi başlıyor...\")\n",
    "pollutant_cols = [col for col in df.columns if df[col].dtype in ['float64', 'int64']]\n",
    "# Ülke sütununu çıkar\n",
    "if 'country' in pollutant_cols: pollutant_cols.remove('country')\n",
    "\n",
    "df[pollutant_cols] = df[pollutant_cols].interpolate(method='time', limit_direction='both')\n",
    "df.fillna(method='ffill', inplace=True); df.fillna(method='bfill', inplace=True)\n",
    "print(\"Eksik veri yönetimi tamamlandı.\")\n",
    "\n",
    "# Aşırı değerleri kırpma\n",
    "print(\"\\nAşırı aykırı değerler %99.9 persentil ile kırpılıyor...\")\n",
    "for col in pollutant_cols:\n",
    "    upper_limit = df[col].quantile(0.999)\n",
    "    df[col] = df[col].clip(upper=upper_limit)\n",
    "    print(f\" '{col}' sütunu, üst sınır '{upper_limit:.2f}' ile kırpıldı.\")\n",
    "\n",
    "# Logaritmik dönüşüm\n",
    "print(\"\\nLogaritmik dönüşüm uygulanıyor...\")\n",
    "for col in pollutant_cols:\n",
    "    df[col] = np.log1p(df[col])\n",
    "\n",
    "print(\"\\nÖznitelik mühendisliği başlıyor...\")\n",
    "df['year'] = df.index.year; df['month'] = df.index.month; df['day_of_week'] = df.index.dayofweek\n",
    "for pollutant in pollutant_cols:\n",
    "    for lag in [1, 3, 7]: df[f'{pollutant}_lag_{lag}d'] = df[pollutant].shift(lag)\n",
    "    for window in [3, 7]: df[f'{pollutant}_roll_mean_{window}d'] = df[pollutant].rolling(window, closed='left').mean()\n",
    "df.fillna(method='bfill', inplace=True)\n",
    "print(\"Öznitelik mühendisliği tamamlandı\")\n",
    "\n",
    "df.to_csv(ENGINEERED_FILE_PATH, index=True)\n",
    "print(f\"\\nTemizlenmiş ve öznitelik mühendisliği yapılmış veri '{ENGINEERED_FILE_PATH}' dosyasına kaydedildi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da4659cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'fi_air_quality_engineered.csv' yüklendi. Boyut: (2886, 57)\n",
      "\n",
      ">>> FI: XGBOOST - NO2 modeli eğitiliyor...\n",
      "-> NO2 için XGBOOST modeli eğitildi ve kaydedildi\n",
      "\n",
      ">>> FI: XGBOOST - O3 modeli eğitiliyor...\n",
      "-> O3 için XGBOOST modeli eğitildi ve kaydedildi\n",
      "\n",
      ">>> FI: XGBOOST - PM10 modeli eğitiliyor...\n",
      "-> PM10 için XGBOOST modeli eğitildi ve kaydedildi\n",
      "\n",
      ">>> FI: XGBOOST - PM25 modeli eğitiliyor...\n",
      "-> PM25 için XGBOOST modeli eğitildi ve kaydedildi\n",
      "\n",
      ">>> FI: XGBOOST - SO2 modeli eğitiliyor...\n",
      "-> SO2 için XGBOOST modeli eğitildi ve kaydedildi\n",
      "\n",
      ">>> FI: RANDOMFOREST - NO2 modeli eğitiliyor...\n",
      "-> NO2 için RANDOMFOREST modeli eğitildi ve kaydedildi\n",
      "\n",
      ">>> FI: RANDOMFOREST - O3 modeli eğitiliyor...\n",
      "-> O3 için RANDOMFOREST modeli eğitildi ve kaydedildi\n",
      "\n",
      ">>> FI: RANDOMFOREST - PM10 modeli eğitiliyor...\n",
      "-> PM10 için RANDOMFOREST modeli eğitildi ve kaydedildi\n",
      "\n",
      ">>> FI: RANDOMFOREST - PM25 modeli eğitiliyor...\n",
      "-> PM25 için RANDOMFOREST modeli eğitildi ve kaydedildi\n",
      "\n",
      ">>> FI: RANDOMFOREST - SO2 modeli eğitiliyor...\n",
      "-> SO2 için RANDOMFOREST modeli eğitildi ve kaydedildi\n",
      "\n",
      ">>> FI: MLP - NO2 modeli eğitiliyor...\n",
      "-> NO2 için MLP modeli eğitildi ve kaydedildi\n",
      "\n",
      ">>> FI: MLP - O3 modeli eğitiliyor...\n",
      "-> O3 için MLP modeli eğitildi ve kaydedildi\n",
      "\n",
      ">>> FI: MLP - PM10 modeli eğitiliyor...\n",
      "-> PM10 için MLP modeli eğitildi ve kaydedildi\n",
      "\n",
      ">>> FI: MLP - PM25 modeli eğitiliyor...\n",
      "-> PM25 için MLP modeli eğitildi ve kaydedildi\n",
      "\n",
      ">>> FI: MLP - SO2 modeli eğitiliyor...\n",
      "-> SO2 için MLP modeli eğitildi ve kaydedildi\n",
      "\n",
      ">>> FI: KNN - NO2 modeli eğitiliyor...\n",
      "-> NO2 için KNN modeli eğitildi ve kaydedildi\n",
      "\n",
      ">>> FI: KNN - O3 modeli eğitiliyor...\n",
      "-> O3 için KNN modeli eğitildi ve kaydedildi\n",
      "\n",
      ">>> FI: KNN - PM10 modeli eğitiliyor...\n",
      "-> PM10 için KNN modeli eğitildi ve kaydedildi\n",
      "\n",
      ">>> FI: KNN - PM25 modeli eğitiliyor...\n",
      "-> PM25 için KNN modeli eğitildi ve kaydedildi\n",
      "\n",
      ">>> FI: KNN - SO2 modeli eğitiliyor...\n",
      "-> SO2 için KNN modeli eğitildi ve kaydedildi\n"
     ]
    }
   ],
   "source": [
    "# BLOK4: TRAİNİNG\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, TimeSeriesSplit\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "import joblib\n",
    "import warnings\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "COUNTRY_CODE = 'fi' \n",
    "ENGINEERED_FILE_PATH = f'{COUNTRY_CODE}_air_quality_engineered.csv'\n",
    "TARGET_POLLUTANTS = ['co', 'no2', 'o3', 'pm10', 'pm25', 'so2']\n",
    "FORECAST_HORIZON = 1\n",
    "\n",
    "# Veriyi yükleme\n",
    "df_engineered = pd.read_csv(ENGINEERED_FILE_PATH, index_col='from_date', parse_dates=True)\n",
    "print(f\"'{ENGINEERED_FILE_PATH}' yüklendi. Boyut: {df_engineered.shape}\")\n",
    "\n",
    "# Model tanımları\n",
    "models = {\n",
    "    \"xgboost\": {\"estimator\": xgb.XGBRegressor(random_state=42), \"params\": {'n_estimators': [100, 300], 'max_depth': [5, 7]}},\n",
    "    \"randomforest\": {\"estimator\": RandomForestRegressor(random_state=42), \"params\": {'n_estimators': [100, 200], 'max_depth': [10, 20]}},\n",
    "    \"mlp\": {\"estimator\": MLPRegressor(random_state=42, max_iter=500, early_stopping=True), \"params\": {'hidden_layer_sizes': [(64, 32)], 'alpha': [0.001, 0.05]}},\n",
    "    \"knn\": {\"estimator\": KNeighborsRegressor(), \"params\": {'n_neighbors': [7, 15], 'weights': ['uniform', 'distance']}}\n",
    "}\n",
    "\n",
    "available_targets = [p for p in TARGET_POLLUTANTS if p in df_engineered.columns]\n",
    "\n",
    "for model_name, model_info in models.items():\n",
    "    for target in available_targets:\n",
    "        print(f\"\\n>>> {COUNTRY_CODE.upper()}: {model_name.upper()} - {target.upper()} modeli eğitiliyor...\")\n",
    "        \n",
    "        # Veri hazırlama\n",
    "        features_to_use = [col for col in df_engineered.columns if col not in TARGET_POLLUTANTS + ['country']]\n",
    "        X = df_engineered[features_to_use].copy()\n",
    "        y = df_engineered[[target]].shift(-FORECAST_HORIZON)\n",
    "        X, y = X.iloc[:-FORECAST_HORIZON], y.iloc[:-FORECAST_HORIZON]\n",
    "        X.dropna(axis=1, how='all', inplace=True); X.fillna(0, inplace=True)\n",
    "        \n",
    "        X_train_full, X_test, y_train_full, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "        \n",
    "        # Test için nesneleri oluşturma ve kaydetme\n",
    "        x_scaler = RobustScaler().fit(X_train_full)\n",
    "        y_scaler = RobustScaler().fit(y_train_full)\n",
    "        k_val = min(20 if model_name == 'knn' else 35, X_train_full.shape[1])\n",
    "        X_train_s = pd.DataFrame(x_scaler.transform(X_train_full), columns=X_train_full.columns)\n",
    "        selector = SelectKBest(score_func=f_regression, k=k_val).fit(X_train_s, y_train_full.values.ravel())\n",
    "        \n",
    "        joblib.dump(x_scaler, f'x_scaler_{model_name}_{target}_{COUNTRY_CODE}.pkl')\n",
    "        joblib.dump(y_scaler, f'y_scaler_{model_name}_{target}_{COUNTRY_CODE}.pkl')\n",
    "        joblib.dump(selector, f'selector_{model_name}_{target}_{COUNTRY_CODE}.pkl')\n",
    "        X_test.to_csv(f'X_test_{target}_{COUNTRY_CODE}.csv')\n",
    "        y_test.to_csv(f'y_test_{target}_{COUNTRY_CODE}.csv')\n",
    "\n",
    "        # Hiperparametre optimizasyonu\n",
    "        X_train_hp_f = selector.transform(X_train_s)\n",
    "        y_train_hp_s = y_scaler.transform(y_train_full)\n",
    "        \n",
    "        tscv = TimeSeriesSplit(n_splits=3)\n",
    "        random_search = RandomizedSearchCV(\n",
    "            estimator=model_info[\"estimator\"], param_distributions=model_info[\"params\"],\n",
    "            n_iter=4, cv=tscv, scoring='neg_root_mean_squared_error', random_state=42, n_jobs=-1\n",
    "        )\n",
    "        random_search.fit(X_train_hp_f, y_train_hp_s.ravel())\n",
    "        best_params = random_search.best_params_\n",
    "        \n",
    "        # Final modeli tüm eğitim verisiyle eğitme ve kaydetme\n",
    "        final_model = model_info[\"estimator\"].set_params(**best_params)\n",
    "        final_model.fit(X_train_hp_f, y_train_hp_s.ravel())\n",
    "        joblib.dump(final_model, f'model_{model_name}_{target}_{COUNTRY_CODE}.pkl')\n",
    "        \n",
    "        print(f\"-> {target.upper()} için {model_name.upper()} modeli eğitildi ve kaydedildi\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
